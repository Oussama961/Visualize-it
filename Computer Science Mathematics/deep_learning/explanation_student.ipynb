{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83ee5f6c",
   "metadata": {},
   "source": [
    "#### Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa1e1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tanserflow.keras import models, layers, optimizers, losses, metrics, datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d6200f",
   "metadata": {},
   "source": [
    "Each library serves a specific purpose:\n",
    "- cv2: OpenCV for computer vision operations\n",
    "- numpy: Efficient numerical computations and array operations\n",
    "- matplotlib.pyplot: Creating visualizations and plots\n",
    "- os: Operating system interactions (though unused in this script)\n",
    "- tensorflow.keras: Deep learning framework components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547f4fd3",
   "metadata": {},
   "source": [
    "#### Data Loading and Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99a778f",
   "metadata": {},
   "outputs": [],
   "source": [
    "(training_images, training_labels), (testing_images, testing_labels) = datasets.cifar10.load_data()\n",
    "training_images = training_images.astype('float32') / 255.0\n",
    "testing_images = testing_images.astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1531b6f2",
   "metadata": {},
   "source": [
    "This section handles the CIFAR-10 dataset geeksforgeeks.org:\n",
    "- Loads the dataset containing:\n",
    "    * 50,000 training images\n",
    "    * 10,000 testing images\n",
    "    * All images are 32×32 pixels with 3 color channels\n",
    "    * 10 distinct classes (airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck)\n",
    "- Normalizes pixel values from [0-255] to [0-1]:\n",
    "    * Original images store pixels as integers (0-255)\n",
    "    * Division by 255 converts to floating-point numbers (0-1)\n",
    "    * This normalization helps neural networks learn more efficiently\n",
    "    * astype('float32') ensures efficient numerical processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3659046b",
   "metadata": {},
   "source": [
    "#### Class Labels Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b259ba25",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "               'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3093794",
   "metadata": {},
   "source": [
    "Creates a mapping between numeric labels (0-9) and class names for better visualization. Each index corresponds to a specific class in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76dec0a1",
   "metadata": {},
   "source": [
    "#### Visualization Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7519f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(9):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.imshow(training_images[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(class_names[training_labels[i][0]])\n",
    "    plt.axis('off')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b868798a",
   "metadata": {},
   "source": [
    "This section creates a 3×3 grid displaying sample images:\n",
    "* Grid Setup:\n",
    "    - `plt.subplot(3, 3, i + 1)` creates a 3×3 grid layout\n",
    "    - Each iteration places an image in the next position\n",
    "* Image Display:\n",
    "    - `plt.imshow()` renders the image\n",
    "    - `cmap=plt.cm.binary` uses grayscale colormap for display\n",
    "    - Images are already normalized (0-1), so no additional scaling needed\n",
    "* Labeling:\n",
    "    - `plt.xlabel()` adds the class name below each image\n",
    "    - `class_names[training_labels[i][0]]` maps the numeric label to text\n",
    "* Cleanup:\n",
    "    - `plt.xticks([])` and `plt.yticks([])` remove axis ticks\n",
    "    - `plt.axis('off')` hides the entire axis frame\n",
    "    - `plt.show()` displays the complete grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cae094c",
   "metadata": {},
   "source": [
    "We need now to train our modele. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e1ca50",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_images = training_images.reshape((50000, 32, 32, 3))\n",
    "training_labels = training_labels.reshape((50000,))\n",
    "testing_images = testing_images.reshape((10000, 32, 32, 3))\n",
    "testing_labels = testing_labels.reshape((10000,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d8d381",
   "metadata": {},
   "source": [
    "Detailed Explanation of Each Reshape Operation\n",
    "1- Training Images Reshape: `training_images = training_images.reshape((50000, 32, 32, 3))`\n",
    "    - Purpose: Ensures consistent 4D structure for CNN input\n",
    "    - Dimensions explained:\n",
    "        * 50,000: Number of training images\n",
    "        * 32×32: Image resolution (width × height)\n",
    "        * 3: Color channels (RGB)\n",
    "    - This format is essential for Convolutional Neural Networks (CNNs) as they expect input data in batches of images with fixed dimensions\n",
    "\n",
    "- 2- Training Labels Reshape: `training_labels = training_labels.reshape((50000,))`\n",
    "    - Purpose: Simplifies label structure into a single dimension\n",
    "    - Effect:\n",
    "        * Converts from potential multi-dimensional shape to simple vector\n",
    "        * Each index corresponds directly to an image\n",
    "        * More efficient for sparse categorical crossentropy loss function\n",
    "        * Maintains alignment with training images (same first dimension)\n",
    "\n",
    "- 3- Testing Images Reshape: `testing_images = testing_images.reshape((10000, 32, 32, 3))`\n",
    "    - Creates identical structure to training images\n",
    "    - Ensures validation/test data matches model expectations\n",
    "    - Dimensions mirror training data except for batch size\n",
    "\n",
    "- 4- Testing Labels Reshape: `testing_labels = testing_labels.reshape((10000,))`\n",
    "    - Matches structure of testing images\n",
    "    - Consistent with training labels format\n",
    "    - Prepared for model evaluation\n",
    "\n",
    "These reshape operations serve several critical purposes: (Practical Implications:)\n",
    "\n",
    "- Model Compatibility:\n",
    "    * CNNs expect fixed-size inputs\n",
    "    * Labels must match batch sizes\n",
    "    * Consistent shapes enable proper broadcasting\n",
    "- Data Alignment:\n",
    "    * Images and labels remain synchronized\n",
    "    * Batch processing becomes straightforward\n",
    "    * Validation splits work correctly\n",
    "- Memory Efficiency:\n",
    "    * Removes unnecessary dimensions\n",
    "    * Optimizes storage layout\n",
    "    * Improves computation efficiency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf02eea",
   "metadata": {},
   "source": [
    "| ASPECT | `RESHAPE()` OPERATION | SLICING OPERATION (`[:20000] # exemple`) |\n",
    "|:--------:|:--------:|:--------:|\n",
    "|  Purpose   |  Changes data arrangement without modifying values   |  Reduces dataset size by selecting subset   |\n",
    "|  Memory Impact   |  No memory reduction (same total elements)   |  Significantly reduces memory usage   |\n",
    "|  Data Preservation   |  Preserves all original data values   |  Discards 66.67% of the training data   |\n",
    "|  Dimensionality  |  Changes array shape while maintaining total elements  |  Maintains original dimensions except for first dimension  |\n",
    "|  Training Impact\t|  Doesn't affect model training capacity  | Reduces training data significantly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e7678b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Using reshape()\n",
    "# Original shape: (50000, 32, 32, 3)\n",
    "training_images = training_images.reshape((50000, 32, 32, 3))\n",
    "print(\"After reshape:\", training_images.shape)  # Still (50000, 32, 32, 3)\n",
    "\n",
    "# Example 2: Using slice\n",
    "# Original shape: (50000, 32, 32, 3)\n",
    "training_images = training_images[:20000]\n",
    "print(\"After slice:\", training_images.shape)   # Now (20000, 32, 32, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147b5af2",
   "metadata": {},
   "source": [
    "Practical Implications:\n",
    "\n",
    "- Model Training Impact:\n",
    "    * reshape(): Maintains full dataset diversity, ideal for training\n",
    "    * [:20000]: Reduces training data significantly, potentially affecting model performance\n",
    "- Memory Usage:\n",
    "    * reshape(): No memory reduction, same total elements\n",
    "    * [:20000]: Uses approximately 40% less memory (20,000 vs 50,000 images)\n",
    "- Common Use Cases:\n",
    "    * reshape(): Typically used for preparing data for specific neural network architectures\n",
    "    * [:20000]: Often used for quick prototyping or testing with smaller datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c778c7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = models.Sequential()\n",
    "models.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "models.add(layers.MaxPooling2D((2, 2)))\n",
    "models.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "models.add(layers.MaxPooling2D((2, 2)))\n",
    "models.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "models.add(layers.Flatten())\n",
    "models.add(layers.Dense(64, activation='relu'))\n",
    "models.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25453d24",
   "metadata": {},
   "source": [
    "* First Convolutional Block: `models.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))`\n",
    "    - Creates 32 filters that slide over the input image\n",
    "    - Each filter is 3×3 pixels in size\n",
    "    - Uses ReLU activation to introduce non-linearity\n",
    "    - Input shape matches CIFAR-10 images (32×32×3)\n",
    "\n",
    "*First Max Pooling Layer: `models.add(layers.MaxPooling2D((2, 2)))`\n",
    "    - Reduces spatial dimensions by half\n",
    "    - Takes maximum value from each 2×2 window\n",
    "    - Helps reduce computational cost\n",
    "    - Maintains important features while reducing dimensions\n",
    "\n",
    "- Second Convolutional Block: `models.add(layers.Conv2D(64, (3, 3), activation='relu'))`\n",
    "    * Doubles the number of filters to 64\n",
    "    * Same 3×3 filter size\n",
    "    * Captures more complex features than first block\n",
    "    * Still uses ReLU activation\n",
    "\n",
    "- Second Max Pooling Layer: `models.add(layers.MaxPooling2D((2, 2)))`\n",
    "    * Another 2×2 downsampling\n",
    "    * Further reduces spatial dimensions\n",
    "    * Helps prevent overfitting\n",
    "    * Maintains translation invariance\n",
    "\n",
    "- Third Convolutional Block: `models.add(layers.Conv2D(64, (3, 3), activation='relu'))`\n",
    "    * Maintains 64 filters\n",
    "    * Final feature extraction layer\n",
    "    * Prepares features for classification\n",
    "    * Same 3×3 filter size for detailed feature capture\n",
    "\n",
    "- Flatten Layer: `models.add(layers.Flatten())`\n",
    "    * Transforms 3D feature maps into 1D array\n",
    "    * Prepares output for dense layers\n",
    "    * No parameters to learn\n",
    "    * Essential transition to fully connected layers\n",
    "\n",
    "- Dense Layers: `models.add(layers.Dense(64, activation='relu'))`, `models.add(layers.Dense(10, activation='softmax'))`\n",
    "    * First dense layer (64 units) processes flattened features\n",
    "    * Uses ReLU for non-linearity\n",
    "    * Final layer has 10 units (one for each CIFAR-10 class)\n",
    "    * Softmax activation ensures probability distribution\n",
    "\n",
    "This architecture is well-suited for CIFAR-10 because: (Practical Implications): \n",
    "- Multiple convolutional blocks capture features at different scales\n",
    "- Progressive downsampling reduces computational cost\n",
    "- Sufficient capacity for 10-class classification\n",
    "- Balanced between complexity and efficiency"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bibenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
